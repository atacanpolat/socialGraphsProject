{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_names = []\n",
    "count = 0\n",
    "for i in G1.nodes:\n",
    "    if i not in all_data[\"characters_infobox\"]:\n",
    "        replace_names.append(i)\n",
    "        count += 1\n",
    "print(replace_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch_header(session, name):\n",
    "    url = \"https://naruto.fandom.com/wiki/{}\".format(name)\n",
    "    \n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                html = await response.text()\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                # Extract the content within the specified span element\n",
    "                span_element = soup.find('span', class_='mw-page-title-main')\n",
    "                header = span_element.text.strip() if span_element else None\n",
    "                \n",
    "                return {'original_name': name, 'header': header}\n",
    "            else:\n",
    "                print(\"URL: {}, Status: {}\".format(url, response.status))\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(\"Error for URL {}: {}\".format(url, e))\n",
    "    \n",
    "    return {'original_name': name, 'header': None}  # Return a dictionary even when header is not found or there is an error\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_header(session, name) for name in replace_names]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results\n",
    "\n",
    "result_records = await main()\n",
    "\n",
    "# Now you can work with the 'result_records' variable as needed\n",
    "# For example, you can iterate through it and print each record:\n",
    "for result in result_records:\n",
    "    print(f\"{result['original_name']}: {result['header']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_node_names = result_records\n",
    "corrected_node_names = {index: value for index, value in enumerate(corrected_node_names)}\n",
    "corrected_node_names.pop(21)\n",
    "corrected_node_names.pop(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/corrected_node_names.json', 'w') as json_file:\n",
    "    json.dump(corrected_node_names, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path_episodes_seasons_characters = '/Users/lukasjonsson/Desktop/DTU/Kandidat/3. semester/Social graphs & interactions/Project/socialGraphsProject/data/episodes_seasons_characters.json'\n",
    "\n",
    "# Open the file and load its contents as a dictionary\n",
    "with open(json_file_path_episodes_seasons_characters, 'r') as file:\n",
    "    episodes_seasons_characters = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming corrected_node_names is a dictionary with 'original_name' and 'header' keys\n",
    "\n",
    "# Iterate over the data and update names\n",
    "for key, episodes in episodes_seasons_characters.items():\n",
    "    for episode in episodes:\n",
    "        characters = episode.get('Characters', [])\n",
    "        for i in range(len(characters)):\n",
    "            for node_id, correction in corrected_node_names.items():\n",
    "                if correction['original_name'] == characters[i]:\n",
    "                    characters[i] = correction['header']\n",
    "\n",
    "# Save the updated data back to the JSON file\n",
    "with open('../data/episodes_seasons_characters_updated.json', 'w') as json_file:\n",
    "    json.dump(episodes_seasons_characters, json_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
